{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando colunas binárias para os gêneros...\n"
     ]
    }
   ],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Carregar os dados dos filmes, avaliações e usuários a partir dos arquivos .dat\n",
    "# Utiliza-se o separador '::' e o parâmetro 'engine=\"python\"' para garantir que o pandas consiga lidar com o delimitador específico\n",
    "movies_df = pd.read_csv('./movie-lens-1m/movies.dat', delimiter='::', engine='python', header=None, names=['MovieId', 'Title', 'Genres'], encoding='latin1')\n",
    "ratings_df = pd.read_csv('./movie-lens-1m/ratings.dat', delimiter='::', engine='python', header=None, names=['UserId', 'MovieId', 'Rating', 'Timestamp'], encoding='latin1')\n",
    "users_df = pd.read_csv('./movie-lens-1m/users.dat', delimiter='::', engine='python', header=None, names=['UserId', 'Gender','AgeRange', 'Occupation', 'Zip'], encoding='latin1')\n",
    "\n",
    "# Função para extrair o ano do título do filme e limpar o título (remover o ano entre parênteses)\n",
    "def extract_year_and_clean_title(title_with_year):\n",
    "    # Extrair o ano (os últimos 5 caracteres são \" (YYYY)\")\n",
    "    year = int(title_with_year[-5:-1])\n",
    "    # Remover os últimos 6 caracteres do título (inclui espaço e parênteses do ano)\n",
    "    cleaned_title = title_with_year[:-6]\n",
    "    return year, cleaned_title\n",
    "\n",
    "# Aplicar a função 'extract_year_and_clean_title' na coluna 'Title' para obter o ano e o título limpo\n",
    "# A função 'apply' é usada para aplicar a função em cada valor da coluna 'Title', e o retorno é dividido em duas colunas ('ReleasedYear' e 'CleanedTitle')\n",
    "movies_df[['ReleasedYear', 'CleanedTitle']] = movies_df['Title'].apply(\n",
    "    lambda x: pd.Series(extract_year_and_clean_title(x))\n",
    ")\n",
    "\n",
    "# Atualizar a coluna 'Title' com o título limpo (sem o ano), se necessário\n",
    "movies_df['Title'] = movies_df['CleanedTitle']\n",
    "# Remover a coluna temporária 'CleanedTitle' após a atualização\n",
    "movies_df.drop(columns=['CleanedTitle'], inplace=True)\n",
    "\n",
    "# Imprimir uma mensagem indicando o início do processo de criação das colunas binárias para os gêneros\n",
    "print(\"Criando colunas binárias para os gêneros...\")\n",
    "\n",
    "# Dividir os gêneros (usando o caractere '|' como delimitador) para identificar todos os gêneros presentes nos filmes\n",
    "genres_split = movies_df['Genres'].str.split('|')\n",
    "# Criar um conjunto de gêneros únicos presentes em todos os filmes\n",
    "unique_genres = set([genre for sublist in genres_split for genre in sublist])\n",
    "\n",
    "# Para cada gênero único, criar uma nova coluna binária no dataframe\n",
    "for genre in unique_genres:\n",
    "    # Se o gênero estiver presente no campo 'Genres', a coluna será 1, caso contrário, 0\n",
    "    movies_df[genre] = movies_df['Genres'].apply(lambda x: 1 if genre in x else 0)\n",
    "\n",
    "# Após a criação das colunas binárias, remover a coluna original 'Genres', pois agora os gêneros estão representados por colunas individuais\n",
    "movies_df.drop(columns=['Genres'], inplace=True)\n",
    "\n",
    "# Realizar a junção (merge) dos dataframes 'ratings_df' e 'movies_df' com base na coluna 'MovieId'\n",
    "# Isso cria um novo dataframe com informações de avaliação e filme combinadas\n",
    "new_df = pd.merge(ratings_df, movies_df, on = 'MovieId')\n",
    "\n",
    "# Realizar uma segunda junção entre o dataframe combinado (new_df) e o dataframe de usuários (users_df) com base na coluna 'UserId'\n",
    "# Isso cria o dataframe final (df) que contém informações completas sobre avaliações, filmes e usuários\n",
    "df = pd.merge(new_df, users_df, on = 'UserId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movies_df = pd.read_csv('./movie-lens-1m/movies.dat', delimiter='::', engine='python', header=None, names=['MovieId', 'Title', 'Genres'], encoding='latin1')\n",
    "ratings_df = pd.read_csv('./movie-lens-1m/ratings.dat', delimiter='::', engine='python', header=None, names=['UserId', 'MovieId', 'Rating', 'Timestamp'], encoding='latin1')\n",
    "users_df = pd.read_csv('./movie-lens-1m/users.dat', delimiter='::', engine='python', header=None, names=['UserId', 'Gender','AgeRange', 'Occupation', 'Zip'], encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieId     int64\n",
      "Title      object\n",
      "Genres     object\n",
      "dtype: object\n",
      "UserId       int64\n",
      "MovieId      int64\n",
      "Rating       int64\n",
      "Timestamp    int64\n",
      "dtype: object\n",
      "UserId         int64\n",
      "Gender        object\n",
      "AgeRange       int64\n",
      "Occupation     int64\n",
      "Zip           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(movies_df.dtypes)\n",
    "print(ratings_df.dtypes)\n",
    "print(users_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Title</th>\n",
       "      <th>ReleasedYear</th>\n",
       "      <th>Western</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Drama</th>\n",
       "      <th>...</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>War</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Action</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>SentimentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>0.477192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>As the gang return to Jumanji to rescue one of...</td>\n",
       "      <td>-0.514916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>-0.818498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>-0.968858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>-0.634570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieId                         Title  ReleasedYear  Western  Crime  \\\n",
       "0        1                    Toy Story           1995        0      0   \n",
       "1        2                      Jumanji           1995        0      0   \n",
       "2        3             Grumpier Old Men           1995        0      0   \n",
       "3        4            Waiting to Exhale           1995        0      0   \n",
       "4        5  Father of the Bride Part II           1995        0      0   \n",
       "\n",
       "   Mystery  Romance  Children's  Horror  Drama  ...  Thriller  Adventure  War  \\\n",
       "0        0        0           1       0      0  ...         0          0    0   \n",
       "1        0        0           1       0      0  ...         0          1    0   \n",
       "2        0        1           0       0      0  ...         0          0    0   \n",
       "3        0        0           0       0      1  ...         0          0    0   \n",
       "4        0        0           0       0      0  ...         0          0    0   \n",
       "\n",
       "   Musical  Action  Comedy  Documentary  Animation  \\\n",
       "0        0       0       1            0          1   \n",
       "1        0       0       0            0          0   \n",
       "2        0       0       1            0          0   \n",
       "3        0       0       1            0          0   \n",
       "4        0       0       1            0          0   \n",
       "\n",
       "                                            Synopsis  SentimentScore  \n",
       "0  Led by Woody, Andy's toys live happily in his ...        0.477192  \n",
       "1  As the gang return to Jumanji to rescue one of...       -0.514916  \n",
       "2  A family wedding reignites the ancient feud be...       -0.818498  \n",
       "3  Cheated on, mistreated and stepped on, the wom...       -0.968858  \n",
       "4  Just when George Banks has recovered from his ...       -0.634570  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar os DataFrames\n",
    "movies_df = pd.read_csv('./movie-lens-1m/movies-with-comment.dat', delimiter='|', engine='python', encoding='utf-8')\n",
    "ratings_df = pd.read_csv('./movie-lens-1m/ratings.dat', delimiter='::', engine='python', header=None, names=['UserId', 'MovieId', 'Rating', 'Timestamp'], encoding='latin1')\n",
    "users_df = pd.read_csv('./movie-lens-1m/users.dat', delimiter='::', engine='python', header=None, names=['UserId', 'Gender','AgeRange', 'Occupation', 'Zip'], encoding='latin1')\n",
    "\n",
    "# Filtrar movies_df para ter apenas sinopses não nulas e não vazias\n",
    "movies_df = movies_df[movies_df['Synopsis'].notna() & (movies_df['Synopsis'].str.strip() != \"\")]\n",
    "\n",
    "# Obter os MovieId válidos\n",
    "valid_movie_ids = movies_df['MovieId'].unique()\n",
    "\n",
    "# Filtrar ratings_df e users_df para conter apenas MovieId válidos\n",
    "ratings_df = ratings_df[ratings_df['MovieId'].isin(valid_movie_ids)]\n",
    "users_df = users_df[users_df['UserId'].isin(ratings_df['UserId'].unique())]\n",
    "\n",
    "# Verificar as primeiras linhas de movies_df\n",
    "movies_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_sinopsis = movies_df\n",
    "\n",
    "def fetch_synopsis(title):\n",
    "    url = f\"https://api.themoviedb.org/3/search/movie\"\n",
    "    params = {\n",
    "        'api_key': \"API_KEY\",\n",
    "        'query': title,\n",
    "        'language': 'en-US'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        print(response.json().get('results', []))\n",
    "        results = response.json().get('results', [])\n",
    "        if results:\n",
    "            return results[0].get('overview', None)\n",
    "    return None\n",
    "\n",
    "movies_with_sinopsis['Synopsis'] = movies_with_sinopsis['Title'].apply(fetch_synopsis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo com sucesso usando UTF-8.\n"
     ]
    }
   ],
   "source": [
    "movies_df.to_csv(\n",
    "    './movie-lens-1m/movies-with-comment.dat',\n",
    "    sep='|',\n",
    "    index=False,\n",
    "    header=True,\n",
    "    encoding='utf-8'  # Alterando para UTF-8\n",
    ")\n",
    "\n",
    "print(\"Arquivo salvo com sucesso usando UTF-8.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando sentimentos com HuggingFace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Guilh\\.cache\\huggingface\\hub\\models--facebook--bart-large-mnli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Função para buscar a sinopse de um filme através da API do The Movie Database (TMDb)\n",
    "def fetch_synopsis(title):\n",
    "    \"\"\"\n",
    "    Busca a sinopse de um filme usando a API do The Movie Database (TMDb).\n",
    "    \n",
    "    Parâmetros:\n",
    "    title (str): O título do filme para o qual a sinopse será buscada.\n",
    "    \n",
    "    Retorna:\n",
    "    str or None: A sinopse do filme se encontrada, ou None caso contrário.\n",
    "    \n",
    "    A função realiza uma requisição GET para a API do TMDb para buscar informações sobre o filme\n",
    "    com o título fornecido. Se a requisição for bem-sucedida e houver resultados, retorna a sinopse\n",
    "    do primeiro filme encontrado. Caso contrário, retorna None.\n",
    "    \n",
    "    Exemplo:\n",
    "    fetch_synopsis(\"The Matrix\") -> \"A computer hacker learns from mysterious rebels about the true nature of his reality...\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Definindo a URL da API para busca de filmes\n",
    "    url = f\"https://api.themoviedb.org/3/search/movie\"\n",
    "    \n",
    "    # Parâmetros da requisição, incluindo chave da API e o título do filme\n",
    "    params = {\n",
    "        'api_key': \"45b79be0f5f7d65f14939f378dec550e\",  # Substitua pela sua chave da API\n",
    "        'query': title,\n",
    "        'language': 'en-US'\n",
    "    }\n",
    "    \n",
    "    # Enviando a requisição GET para a API\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Se a requisição for bem-sucedida (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Imprimindo o resultado da API para depuração\n",
    "        print(response.json().get('results', []))\n",
    "        \n",
    "        # Obtendo os resultados da resposta JSON\n",
    "        results = response.json().get('results', [])\n",
    "        \n",
    "        # Se houver resultados, retorna a sinopse do primeiro filme encontrado\n",
    "        if results:\n",
    "            return results[0].get('overview', None)\n",
    "    \n",
    "    # Se não houver resultados ou erro, retorna None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Title</th>\n",
       "      <th>ReleasedYear</th>\n",
       "      <th>Western</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeRange</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Zip</th>\n",
       "      <th>UserId_encoded</th>\n",
       "      <th>MovieId_encoded</th>\n",
       "      <th>ReleasedYear_normalized</th>\n",
       "      <th>Rating_normalized</th>\n",
       "      <th>SentimentScore_normalized</th>\n",
       "      <th>Mean_Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>1975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>0</td>\n",
       "      <td>1084</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.259244</td>\n",
       "      <td>0.186696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "      <td>James and the Giant Peach</td>\n",
       "      <td>1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.846919</td>\n",
       "      <td>0.144771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "      <td>My Fair Lady</td>\n",
       "      <td>1964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>0</td>\n",
       "      <td>838</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.718295</td>\n",
       "      <td>0.098922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>Erin Brockovich</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>0</td>\n",
       "      <td>3092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.985865</td>\n",
       "      <td>0.188404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "      <td>Bug's Life, A</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>0</td>\n",
       "      <td>2116</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.814400</td>\n",
       "      <td>0.146802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  MovieId  Rating  Timestamp                             Title  \\\n",
       "0       1     1193       5  978300760  One Flew Over the Cuckoo's Nest    \n",
       "1       1      661       3  978302109        James and the Giant Peach    \n",
       "2       1      914       3  978301968                     My Fair Lady    \n",
       "3       1     3408       4  978300275                  Erin Brockovich    \n",
       "4       1     2355       5  978824291                    Bug's Life, A    \n",
       "\n",
       "   ReleasedYear  Western  Crime  Mystery  Romance  ...  Gender  AgeRange  \\\n",
       "0          1975        0      0        0        0  ...       F         1   \n",
       "1          1996        0      0        0        0  ...       F         1   \n",
       "2          1964        0      0        0        1  ...       F         1   \n",
       "3          2000        0      0        0        0  ...       F         1   \n",
       "4          1998        0      0        0        0  ...       F         1   \n",
       "\n",
       "   Occupation    Zip  UserId_encoded  MovieId_encoded  \\\n",
       "0          10  48067               0             1084   \n",
       "1          10  48067               0              630   \n",
       "2          10  48067               0              838   \n",
       "3          10  48067               0             3092   \n",
       "4          10  48067               0             2116   \n",
       "\n",
       "   ReleasedYear_normalized  Rating_normalized  SentimentScore_normalized  \\\n",
       "0                 0.691358               1.00                   0.259244   \n",
       "1                 0.950617               0.50                   0.846919   \n",
       "2                 0.555556               0.50                   0.718295   \n",
       "3                 1.000000               0.75                   0.985865   \n",
       "4                 0.975309               1.00                   0.814400   \n",
       "\n",
       "   Mean_Similarity  \n",
       "0         0.186696  \n",
       "1         0.144771  \n",
       "2         0.098922  \n",
       "3         0.188404  \n",
       "4         0.146802  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Guilh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"recommender_model_with_sentiment_and_similarity\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"recommender_model_with_sentiment_and_similarity\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ movie_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">302,050</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">179,750</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ content_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │ content_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">164</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,120</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ movie_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │    \u001b[38;5;34m302,050\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │    \u001b[38;5;34m179,750\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ content_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,408\u001b[0m │ content_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m164\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m21,120\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">515,465</span> (1.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m515,465\u001b[0m (1.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">515,081</span> (1.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m515,081\u001b[0m (1.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o modelo...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['user_input', 'movie_input', 'content_input']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 2.1662 - mae: 0.9233 - val_loss: 0.8759 - val_mae: 0.7397\n",
      "Epoch 2/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3ms/step - loss: 0.8732 - mae: 0.7315 - val_loss: 0.8391 - val_mae: 0.7154\n",
      "Epoch 3/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 0.8518 - mae: 0.7228 - val_loss: 0.8306 - val_mae: 0.7129\n",
      "Epoch 4/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3ms/step - loss: 0.8428 - mae: 0.7190 - val_loss: 0.8294 - val_mae: 0.7102\n",
      "Epoch 5/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3ms/step - loss: 0.8354 - mae: 0.7160 - val_loss: 0.8199 - val_mae: 0.7088\n",
      "Epoch 6/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 0.8326 - mae: 0.7152 - val_loss: 0.8203 - val_mae: 0.7090\n",
      "Epoch 7/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 0.8320 - mae: 0.7142 - val_loss: 0.8176 - val_mae: 0.7084\n",
      "Epoch 8/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 0.8262 - mae: 0.7112 - val_loss: 0.8208 - val_mae: 0.7115\n",
      "Epoch 9/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 0.8258 - mae: 0.7117 - val_loss: 0.8128 - val_mae: 0.7077\n",
      "Epoch 10/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 0.8239 - mae: 0.7103 - val_loss: 0.8151 - val_mae: 0.7026\n",
      "Epoch 11/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3ms/step - loss: 0.8225 - mae: 0.7095 - val_loss: 0.8132 - val_mae: 0.7038\n",
      "Epoch 12/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3ms/step - loss: 0.8196 - mae: 0.7080 - val_loss: 0.8119 - val_mae: 0.7045\n",
      "Epoch 13/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3ms/step - loss: 0.8196 - mae: 0.7078 - val_loss: 0.8146 - val_mae: 0.7104\n",
      "Epoch 14/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3ms/step - loss: 0.8192 - mae: 0.7077 - val_loss: 0.8124 - val_mae: 0.7020\n",
      "Epoch 15/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 0.8160 - mae: 0.7068 - val_loss: 0.8084 - val_mae: 0.7000\n",
      "Epoch 16/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 0.8147 - mae: 0.7062 - val_loss: 0.8142 - val_mae: 0.7009\n",
      "Epoch 17/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 0.8166 - mae: 0.7061 - val_loss: 0.8164 - val_mae: 0.7065\n",
      "Epoch 18/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3ms/step - loss: 0.8122 - mae: 0.7046 - val_loss: 0.8039 - val_mae: 0.6989\n",
      "Epoch 19/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 0.8145 - mae: 0.7054 - val_loss: 0.8035 - val_mae: 0.7011\n",
      "Epoch 20/20\n",
      "\u001b[1m12355/12355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3ms/step - loss: 0.8107 - mae: 0.7036 - val_loss: 0.8161 - val_mae: 0.7077\n",
      "Treinamento concluído.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Função para carregar os dados de filmes, avaliações e usuários\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Função para carregar os dados de filmes, avaliações e usuários\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Carrega os dados de filmes, avaliações e usuários a partir de arquivos CSV.\n",
    "\n",
    "    Retorna:\n",
    "        tuple: DataFrames de filmes, avaliações e usuários, respectivamente.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        movies_df = pd.read_csv('./movie-lens-1m/movies-with-comment.dat', delimiter='|', engine='python', encoding='utf-8')\n",
    "        ratings_df = pd.read_csv('./ratings_updated.csv', delimiter=',', engine='python', encoding='utf-8')\n",
    "        users_df = pd.read_csv('./users_updated.csv', delimiter=',', engine='python', encoding='utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar dados: {e}\")\n",
    "        return None, None, None\n",
    "    return movies_df, ratings_df, users_df\n",
    "\n",
    "# Função para pré-processar os dados, filtrando e normalizando\n",
    "def preprocess_data(movies_df, ratings_df, users_df):\n",
    "    \"\"\"\n",
    "    Pré-processa os dados, filtrando e normalizando as sinopses de filmes e avaliações.\n",
    "\n",
    "    Parâmetros:\n",
    "        movies_df (DataFrame): DataFrame contendo os dados dos filmes.\n",
    "        ratings_df (DataFrame): DataFrame contendo os dados das avaliações.\n",
    "        users_df (DataFrame): DataFrame contendo os dados dos usuários.\n",
    "\n",
    "    Retorna:\n",
    "        tuple: DataFrame pré-processado, DataFrame de filmes, encoders de usuário e de filme.\n",
    "    \"\"\"\n",
    "    movies_df = movies_df[movies_df['Synopsis'].notna() & (movies_df['Synopsis'].str.strip() != \"\")]\n",
    "    valid_movie_ids = ratings_df['MovieId'].unique()\n",
    "    movies_df = movies_df[movies_df['MovieId'].isin(valid_movie_ids)]\n",
    "    ratings_df = ratings_df[ratings_df['MovieId'].isin(valid_movie_ids)]\n",
    "    users_df = users_df[users_df['UserId'].isin(ratings_df['UserId'].unique())]\n",
    "\n",
    "    new_df = pd.merge(ratings_df, movies_df, on='MovieId')\n",
    "    df = pd.merge(new_df, users_df, on='UserId')\n",
    "\n",
    "    user_encoder = LabelEncoder()\n",
    "    movie_encoder = LabelEncoder()\n",
    "    df['UserId_encoded'] = user_encoder.fit_transform(df['UserId'])\n",
    "    df['MovieId_encoded'] = movie_encoder.fit_transform(df['MovieId'])\n",
    "\n",
    "    np.save('user_encoder_classes.npy', user_encoder.classes_)\n",
    "    np.save('movie_encoder_classes.npy', movie_encoder.classes_)\n",
    "\n",
    "    if 'ReleasedYear' in df.columns:\n",
    "        released_year_min = df['ReleasedYear'].min()\n",
    "        released_year_max = df['ReleasedYear'].max()\n",
    "        df['ReleasedYear_normalized'] = (df['ReleasedYear'] - released_year_min) / (released_year_max - released_year_min)\n",
    "        np.save('scaler_released_year_min_max.npy', [released_year_min, released_year_max])\n",
    "\n",
    "    if 'SentimentScore' in df.columns:\n",
    "        sentiment_score_min = df['SentimentScore'].min()\n",
    "        sentiment_score_max = df['SentimentScore'].max()\n",
    "        df['SentimentScore_normalized'] = (df['SentimentScore'] - sentiment_score_min) / (sentiment_score_max - sentiment_score_min)\n",
    "        np.save('scaler_sentiment_score_min_max.npy', [sentiment_score_min, sentiment_score_max])\n",
    "\n",
    "    return df, movies_df, user_encoder, movie_encoder\n",
    "\n",
    "# Função para gerar embeddings das sinopses dos filmes usando SentenceTransformer\n",
    "def generate_embeddings(movies_df):\n",
    "    \"\"\"\n",
    "    Gera embeddings das sinopses dos filmes usando SentenceTransformer.\n",
    "\n",
    "    Parâmetros:\n",
    "        movies_df (DataFrame): DataFrame contendo os dados dos filmes.\n",
    "\n",
    "    Retorna:\n",
    "        DataFrame: DataFrame dos filmes com a média de similaridade adicionada.\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(movies_df['Synopsis'].dropna().tolist())\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    similarity_mean = similarity_matrix.mean(axis=1)\n",
    "    movies_df['Mean_Similarity'] = similarity_mean\n",
    "    return movies_df\n",
    "\n",
    "# Função para garantir que todos os filmes e usuários com avaliações estejam presentes no conjunto de treinamento\n",
    "def ensure_all_movies_and_users_in_train(df, user_col, movie_col, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Garante que todos os filmes e usuários com avaliações estejam presentes no conjunto de treinamento.\n",
    "\n",
    "    Parâmetros:\n",
    "        df (DataFrame): DataFrame contendo os dados completos.\n",
    "        user_col (str): Nome da coluna de identificadores de usuário.\n",
    "        movie_col (str): Nome da coluna de identificadores de filme.\n",
    "        test_size (float): Proporção dos dados para o conjunto de teste.\n",
    "        random_state (int): Semente para reprodutibilidade.\n",
    "\n",
    "    Retorna:\n",
    "        tuple: DataFrame de treinamento e DataFrame de teste.\n",
    "    \"\"\"\n",
    "    unique_movies = df.groupby(movie_col).first().reset_index()\n",
    "    unique_users = df.groupby(user_col).first().reset_index()\n",
    "    unique_df = pd.concat([unique_movies, unique_users]).drop_duplicates()\n",
    "    remaining_df = df.drop(unique_df.index)\n",
    "    train_remaining, test_set = train_test_split(remaining_df, test_size=test_size, random_state=random_state)\n",
    "    train_set = pd.concat([train_remaining, unique_df]).drop_duplicates()\n",
    "    train_set = shuffle(train_set, random_state=random_state)\n",
    "    return train_set, test_set\n",
    "\n",
    "# Função para construir e treinar o modelo de recomendação com características de conteúdo\n",
    "def build_and_train_model(df, content_features):\n",
    "    \"\"\"\n",
    "    Constrói e treina o modelo de recomendação com características de conteúdo.\n",
    "\n",
    "    Parâmetros:\n",
    "        df (DataFrame): DataFrame contendo os dados de entrada.\n",
    "        content_features (list): Lista de características de conteúdo.\n",
    "\n",
    "    Retorna:\n",
    "        Model: Modelo de recomendação treinado.\n",
    "    \"\"\"\n",
    "    num_users = df['UserId_encoded'].nunique()\n",
    "    num_movies = df['MovieId_encoded'].nunique()\n",
    "    embedding_dim = 50\n",
    "\n",
    "    user_input = Input(shape=(1,), name='user_input')\n",
    "    movie_input = Input(shape=(1,), name='movie_input')\n",
    "    content_input = Input(shape=(len(content_features),), name='content_input')\n",
    "\n",
    "    user_embedding = Embedding(num_users, embedding_dim)(user_input)\n",
    "    movie_embedding = Embedding(num_movies, embedding_dim, input_length=1)(movie_input)\n",
    "\n",
    "    user_vector = Flatten()(user_embedding)\n",
    "    movie_vector = Flatten()(movie_embedding)\n",
    "\n",
    "    content_dense = Dense(64, activation='relu')(content_input)\n",
    "\n",
    "    x = Concatenate()([user_vector, movie_vector, content_dense])\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=[user_input, movie_input, content_input], outputs=output, name=\"recommender_model_with_sentiment_and_similarity\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# Função para carregar recursos salvos, como o modelo e os encoders\n",
    "def load_saved_resources():\n",
    "    \"\"\"\n",
    "    Carrega o modelo treinado e os encoders salvos a partir de arquivos.\n",
    "\n",
    "    Retorna:\n",
    "        tuple: Modelo, encoders de usuário e de filme, valores mínimos e máximos de ano de lançamento e score de sentimento.\n",
    "    \"\"\"\n",
    "    model = load_model('best_model_with_sentiment_and_similarity.keras')\n",
    "\n",
    "    user_encoder_classes = np.load('user_encoder_classes.npy')\n",
    "    movie_encoder_classes = np.load('movie_encoder_classes.npy')\n",
    "    released_year_min, released_year_max = np.load('scaler_released_year_min_max.npy')\n",
    "    sentiment_score_min, sentiment_score_max = np.load('scaler_sentiment_score_min_max.npy')\n",
    "\n",
    "    user_encoder = LabelEncoder()\n",
    "    user_encoder.classes_ = user_encoder_classes\n",
    "    movie_encoder = LabelEncoder()\n",
    "    movie_encoder.classes_ = movie_encoder_classes\n",
    "\n",
    "    return model, user_encoder, movie_encoder, released_year_min, released_year_max, sentiment_score_min, sentiment_score_max\n",
    "\n",
    "# Código principal\n",
    "movies_df, ratings_df, users_df = load_data()\n",
    "\n",
    "df, movies_df, user_encoder, movie_encoder = preprocess_data(movies_df, ratings_df, users_df)\n",
    "movies_df = generate_embeddings(movies_df)\n",
    "\n",
    "# Adicionar a média da similaridade ao DataFrame\n",
    "df = pd.merge(df, movies_df[['MovieId', 'Mean_Similarity']], on='MovieId', how='left')\n",
    "\n",
    "# Dividir o dataset em treinamento e teste\n",
    "train_df, test_df = ensure_all_movies_and_users_in_train(\n",
    "    df, user_col='UserId_encoded', movie_col='MovieId_encoded', test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Definir as características de conteúdo\n",
    "content_features = ['ReleasedYear_normalized', 'SentimentScore_normalized'] + [\n",
    "    'Western', 'Crime', 'Mystery', 'Romance', \"Children's\", 'Horror', 'Drama', 'Fantasy', 'Sci-Fi',\n",
    "    'Film-Noir', 'Thriller', 'Adventure', 'War', 'Musical', 'Action', 'Comedy', 'Documentary', 'Animation', 'Mean_Similarity'\n",
    "]\n",
    "\n",
    "# Definir as variáveis de entrada para o modelo\n",
    "X_train_user = train_df['UserId_encoded']\n",
    "X_test_user = test_df['UserId_encoded']\n",
    "X_train_movie = train_df['MovieId_encoded']\n",
    "X_test_movie = test_df['MovieId_encoded']\n",
    "X_train_content = train_df[content_features].values\n",
    "X_test_content = test_df[content_features].values\n",
    "y_train = train_df['Rating'].values\n",
    "y_test = test_df['Rating'].values\n",
    "\n",
    "# Construir o modelo\n",
    "model = build_and_train_model(df, content_features)\n",
    "\n",
    "# Definir callbacks para treinamento\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_checkpoint = ModelCheckpoint('best_model_with_sentiment_and_similarity.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "print(\"Treinando o modelo...\")\n",
    "history = model.fit(\n",
    "    [X_train_user, X_train_movie, X_train_content], y_train,\n",
    "    validation_data=([X_test_user, X_test_movie, X_test_content], y_test),\n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Treinamento concluído.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def load_saved_resources():\n",
    "    \"\"\"\n",
    "    Carrega o modelo salvo, os encoders e valores de normalização a partir de arquivos.\n",
    "\n",
    "    Retorna:\n",
    "        tuple: Modelo, encoders de usuário e de filme, valores mínimos e máximos de ano de lançamento e score de sentimento.\n",
    "    \"\"\"\n",
    "    model = load_model('best_model_with_sentiment_and_similarity.keras')\n",
    "    released_year_min, released_year_max = np.load('scaler_released_year_min_max.npy')\n",
    "    sentiment_score_min, sentiment_score_max = np.load('scaler_sentiment_score_min_max.npy')\n",
    "    user_encoder_classes = np.load('user_encoder_classes.npy', allow_pickle=True)\n",
    "    movie_encoder_classes = np.load('movie_encoder_classes.npy', allow_pickle=True)\n",
    "    user_encoder = LabelEncoder()\n",
    "    user_encoder.classes_ = user_encoder_classes\n",
    "    movie_encoder = LabelEncoder()\n",
    "    movie_encoder.classes_ = movie_encoder_classes\n",
    "    return model, user_encoder, movie_encoder, released_year_min, released_year_max, sentiment_score_min, sentiment_score_max\n",
    "\n",
    "def normalize(value, min_val, max_val):\n",
    "    \"\"\"\n",
    "    Normaliza valores manualmente.\n",
    "\n",
    "    Parâmetros:\n",
    "        value (float): Valor a ser normalizado.\n",
    "        min_val (float): Valor mínimo para normalização.\n",
    "        max_val (float): Valor máximo para normalização.\n",
    "\n",
    "    Retorna:\n",
    "        float: Valor normalizado.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):  # Lidando com valores ausentes\n",
    "        return 0  # Valor padrão para normalização\n",
    "    return (value - min_val) / (max_val - min_val)\n",
    "\n",
    "def extract_content_features(movies_df):\n",
    "    \"\"\"\n",
    "    Extrai a lista de colunas usadas como características de conteúdo no modelo.\n",
    "\n",
    "    Parâmetros:\n",
    "        movies_df (DataFrame): DataFrame contendo os dados dos filmes.\n",
    "\n",
    "    Retorna:\n",
    "        list: Lista de colunas características de conteúdo.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        'Western', 'Crime', 'Mystery',\n",
    "        'Romance', \"Children's\", 'Horror', 'Drama', 'Fantasy', 'Sci-Fi', 'Film-Noir', 'Thriller',\n",
    "        'Adventure', 'War', 'Musical', 'Action', 'Comedy', 'Documentary', 'Animation', 'Mean_Similarity'\n",
    "    ]\n",
    "\n",
    "def predict_ratings_for_unrated_movies(user_id, movies_df, df):\n",
    "    \"\"\"\n",
    "    Prediz as avaliações para filmes ainda não avaliados por um usuário específico.\n",
    "\n",
    "    Parâmetros:\n",
    "        user_id (int): Identificador do usuário.\n",
    "        movies_df (DataFrame): DataFrame contendo os dados dos filmes.\n",
    "        df (DataFrame): DataFrame contendo as avaliações dos usuários.\n",
    "\n",
    "    Retorna:\n",
    "        None\n",
    "    \"\"\"\n",
    "    model, user_encoder, movie_encoder, released_year_min, released_year_max, sentiment_score_min, sentiment_score_max = load_saved_resources()\n",
    "    rated_movies = df[df['UserId'] == user_id]['MovieId']\n",
    "    unrated_movies_df = movies_df[~movies_df['MovieId'].isin(rated_movies)]\n",
    "    content_features_columns = extract_content_features(movies_df)\n",
    "    predictions = []\n",
    "\n",
    "    for _, movie_row in unrated_movies_df.iterrows():\n",
    "        movie_id = movie_row['MovieId']\n",
    "        released_year = movie_row['ReleasedYear']\n",
    "        sentiment_score = movie_row.get('SentimentScore', 0)\n",
    "        released_year_normalized = normalize(released_year, released_year_min, released_year_max)\n",
    "        sentiment_score_normalized = normalize(sentiment_score, sentiment_score_min, sentiment_score_max)\n",
    "        content_features = movie_row[content_features_columns].values\n",
    "        content_input_prepared = np.array([released_year_normalized, sentiment_score_normalized] + content_features.tolist()).reshape(1, -1)\n",
    "        user_encoded = user_encoder.transform([user_id])[0]\n",
    "        movie_encoded = movie_encoder.transform([movie_id])[0]\n",
    "        predicted_rating = model.predict([np.array([user_encoded]), np.array([movie_encoded]), content_input_prepared], verbose=0)[0][0]\n",
    "        predictions.append((movie_id, predicted_rating, movie_row))\n",
    "\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    genre_top_movies = {genre: [] for genre in movies_df.columns if genre not in ['MovieId', 'Title', 'ReleasedYear', 'SentimentScore', 'Synopsis', 'Mean_Similarity']}\n",
    "\n",
    "    for movie_id, predicted_rating, movie_row in predictions:\n",
    "        title = movie_row['Title']\n",
    "        genres = [col for col in movies_df.columns if col != 'MovieId' and col != 'Title' and col != 'ReleasedYear' and col != 'SentimentScore' and movie_row[col] == 1]\n",
    "        \n",
    "        for genre in genres:\n",
    "            genre_top_movies[genre].append((title, predicted_rating))\n",
    "\n",
    "    # Lista para armazenar os dados\n",
    "    genre_data = []\n",
    "\n",
    "    # Iterar pelos gêneros e filmes\n",
    "    for genre, movies in genre_top_movies.items():\n",
    "        # Ordenar os filmes por previsão de classificação e pegar os 5 melhores\n",
    "        top_5_movies = sorted(movies, key=lambda x: x[1], reverse=True)[:5]\n",
    "        \n",
    "        # Adicionar os dados para cada filme na lista\n",
    "        for title, rating in top_5_movies:\n",
    "            genre_data.append({'Gênero': genre, 'Título': title, 'Previsão de Classificação': rating})\n",
    "\n",
    "    # Criar o DataFrame a partir da lista de dicionários\n",
    "    df_top_movies = pd.DataFrame(genre_data)\n",
    "\n",
    "    # Exibir o DataFrame\n",
    "    return df_top_movies\n",
    "\n",
    "user_id = \"6041\"  # ID do usuário que você quer recomendar os filmes\n",
    "\n",
    "# Chama a função para obter o top 5 de filmes para cada gênero\n",
    "df_top_movies = predict_ratings_for_unrated_movies(user_id, movies_df, df)\n",
    "\n",
    "df_top_movies.he()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [27/Nov/2024 23:10:57] \"GET /avaliar/6041 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "movies_df = pd.read_csv('./movie-lens-1m/movies-with-comment.dat', delimiter='|', engine='python', encoding='utf-8')\n",
    "ratings_df = users_df.to_csv('./users_updated.csv', index=False)\n",
    "users_df.to_csv('./users_updated.csv', index=False)\n",
    "\n",
    "# Função para adicionar avaliações\n",
    "def adicionar_avaliacoes(ratings_df, user_id, avaliacoes):\n",
    "    for movie_id, rating in avaliacoes.items():\n",
    "        new_row = {\n",
    "            'UserId': user_id,\n",
    "            'MovieId': movie_id,\n",
    "            'Rating': rating,\n",
    "            'Timestamp': pd.Timestamp.now().timestamp()\n",
    "        }\n",
    "        ratings_df = pd.concat([ratings_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    return ratings_df\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return redirect(url_for('cadastrar_usuario'))\n",
    "\n",
    "@app.route('/cadastrar', methods=['GET', 'POST'])\n",
    "def cadastrar_usuario():\n",
    "    global users_df\n",
    "    if request.method == 'POST':\n",
    "        gender = request.form['gender']\n",
    "        age_range = request.form['age_range']\n",
    "        occupation = request.form['occupation']\n",
    "        zip_code = request.form['zip_code']\n",
    "        new_user_id = users_df['UserId'].max() + 1 if not users_df.empty else 1\n",
    "        new_row = {'UserId': new_user_id, 'Gender': gender, 'AgeRange': age_range, 'Occupation': occupation, 'Zip': zip_code}\n",
    "        users_df = pd.concat([users_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        return render_template('usuario_cadastrado.html', user_id=new_user_id)\n",
    "    return render_template('cadastrar_usuario.html')\n",
    "\n",
    "@app.route('/avaliar/<int:user_id>', methods=['GET', 'POST'])\n",
    "def avaliar_filmes(user_id):\n",
    "    global movies_df, ratings_df\n",
    "    generos = ['Western', 'Crime', 'Mystery', 'Romance', 'Children\\'s', 'Horror', 'Drama', 'Fantasy', 'Sci-Fi', 'Film-Noir', 'Thriller', 'Adventure', 'War', 'Musical', 'Action', 'Comedy', 'Documentary', 'Animation']\n",
    "    filmes_por_genero = {genero: movies_df[movies_df[genero] == 1][['MovieId', 'Title']].to_dict(orient='records') for genero in generos}\n",
    "    sucesso = False\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        genero_selecionado = request.form.get('genero')\n",
    "        if genero_selecionado in filmes_por_genero:\n",
    "            filmes = filmes_por_genero[genero_selecionado]\n",
    "        else:\n",
    "            filmes = []\n",
    "\n",
    "        avaliacoes = {}\n",
    "        for movie in filmes:\n",
    "            movie_id = movie['MovieId']\n",
    "            rating = request.form.get(str(movie_id))\n",
    "            if rating:\n",
    "                avaliacoes[movie_id] = int(rating)\n",
    "\n",
    "        ratings_df = adicionar_avaliacoes(ratings_df, user_id, avaliacoes)\n",
    "        sucesso = True\n",
    "\n",
    "    return render_template('avaliar_filmes.html', user_id=user_id, filmes_por_genero=filmes_por_genero, generos=generos, sucesso=sucesso)\n",
    "\n",
    "@app.route('/finalizar_avaliacoes', methods=['POST'])\n",
    "def finalizar_avaliacoes():\n",
    "    ratings_df.to_csv('./ratings_updated.csv', index=False)\n",
    "    users_df.to_csv('./users_updated.csv', index=False)\n",
    "    ratings_df.to_csv('./ratings_updated-backup.csv', index=False)\n",
    "    users_df.to_csv('./users_updated-backup.csv', index=False)\n",
    "    shutdown_server()\n",
    "    return 'Aplicação finalizada. As avaliações foram salvas com sucesso.'\n",
    "\n",
    "def shutdown_server():\n",
    "    # Finalizando o servidor Flask\n",
    "    func = request.environ.get('werkzeug.server.shutdown')\n",
    "    if func:\n",
    "        func()\n",
    "    os._exit(0)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 5000, app, use_reloader=False, use_debugger=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df[users_df[user_id] == 6041]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
